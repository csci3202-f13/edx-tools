# Gather data on student progress by scraping edX course site as an instructor

# TODO:
#  Add options for setting $do_progress and $do_detail.  Currently just gets progress report, but could get detailed submission history
#  Login via password and get our own cookies
#  Add test cases

# Default is to just get the progress reports
do_progress=${do_progress:-"yes"}
do_detail=${do_detail:-"no"}

ts=$(date "+%Y%m%dT%H%M%S")

# Read in local course-specific values for $courseserver, $coursepath, $cookie, $users, $problems etc
config=~/config/edx-tools/config
. $config  ||  echo First you need to create $config, based on config-example

# Gather latest progress reports for each userid, via urls like:
#  https://edge.edx.org/courses/BerkeleyX/CS188x-17/2013_T3/progress/5020/
if [ "$do_progress" = "yes" ]; then
    mkdir -p progress

    for userid in $userids; do
        echo progress for userid: $userid
	    curl -k -s --cookie "$cookie" $courseserver/$coursepath/progress/$userid/ > progress/$userid.$ts.html
    done
fi

# Note: need to add command-line arguments and option testing here (or just change false to true....)
# Get detailed submission history and results for each user for given problems
if [ "$do_detail" = "yes" ]; then
  for problem in $problems; do
    mkdir -p $problem
    for username in $users; do
      echo problem: $problem user: $username
      curl -s --cookie "$cookie" $courseserver/$coursepath/submission_history/$username/i4x://$coursepath/problem/$problem > $problem/$username.$ts.html
    done
  done
fi
